# EEF Model - Yang et al. (2025)
# Exploration-Exploitation with Forgetting
#
# Key equations from the paper:
#   Value:       V(t) = G(t)^theta - |L(t)|^theta
#   Exploit:     E_i(t+1) = (1-lambda)*E_i(t) + V(t)  if chosen
#                E_j(t+1) = (1-lambda)*E_j(t)         if unchosen
#   Explore:     X_i(t+1) = 0                         if chosen
#                X_j(t+1) = lambda*X_j(t) + (1-lambda)*phi  if unchosen
#   Choice:      P(d) = softmax(c * [E(d) + X(d)])
#
# The forgetting rate lambda controls how fast values decay.
# High lambda = fast forgetting = more exploration-driven behavior.

model {

  # group-level priors
  mu_theta  ~ dnorm(0,1)T(1.0E-6, 1)   # theta: value sensitivity (0,1]
  mu_lambda ~ dnorm(0,1)T(0,1)         # lambda: forgetting rate [0,1]
  mu_phi    ~ dnorm(0,1)T(-5,5)        # phi: exploration bonus
  mu_cons   ~ dnorm(0,1)T(0,5)         # c (before transform): consistency

  # precision parameters (JAGS uses precision = 1/variance)
  lambda_theta  ~ dgamma(1, 0.5)
  lambda_lambda ~ dgamma(1, 0.5)
  lambda_phi    ~ dgamma(1, 0.5)
  lambda_cons   ~ dgamma(1, 0.5)

  for (s in 1:nsubs) {

    # individual parameters from hierarchical normal
    theta[s] ~ dnorm(mu_theta,  lambda_theta)T(1.0E-6, 1)
    lam[s]   ~ dnorm(mu_lambda, lambda_lambda)T(0,1)
    phi[s]   ~ dnorm(mu_phi,    lambda_phi)T(-5,5)
    cons[s]  ~ dnorm(mu_cons,   lambda_cons)T(0,5)

    # inverse temperature: C = 3^c - 1
    # this maps c in [0,5] to C in [0,242], giving good sensitivity range
    C[s] <- pow(3, cons[s]) - 1

    # E(1) = 0, X(1) = 0 for all decks
    for (d in 1:4) {
      Exploit[s,1,d] <- 0
      Explore[s,1,d] <- 0
    }

    for (t in 2:ntrials[s]) {

      # V(t) = G(t-1)^theta - |L(t-1)|^theta
      # symmetric value function for gains and losses
      V[s,t] <- pow(Gain[s,t-1], theta[s]) - pow(abs(Loss[s,t-1]), theta[s])

      for (d in 1:4) {

        # exploitation update (Eq 4-5 in paper):
        # chosen:   E_i(t) = (1-lambda)*E_i(t-1) + V(t)
        # unchosen: E_j(t) = (1-lambda)*E_j(t-1)
        Exploit_decay[s,t,d]  <- (1 - lam[s]) * Exploit[s,t-1,d]
        Exploit_chosen[s,t,d] <- (1 - lam[s]) * Exploit[s,t-1,d] + V[s,t]
        Exploit[s,t,d] <- ifelse(d == x[s,t-1], Exploit_chosen[s,t,d], Exploit_decay[s,t,d])

        # exploration update (Eq 6-7 in paper):
        # chosen:   X_i(t) = 0  (reset after sampling)
        # unchosen: X_j(t) = lambda*X_j(t-1) + (1-lambda)*phi
        Explore_unchosen[s,t,d] <- lam[s] * Explore[s,t-1,d] + (1 - lam[s]) * phi[s]
        Explore[s,t,d] <- ifelse(d == x[s,t-1], 0, Explore_unchosen[s,t,d])

        # total value: Q(d) = E(d) + X(d)
        TotalVal[s,t,d] <- Exploit[s,t,d] + Explore[s,t,d]

        # softmax input scaled by inverse temperature
        a[s,t,d] <- C[s] * TotalVal[s,t,d]
      }

      # numerically stable softmax: subtract max before exp
      amax[s,t] <- max(a[s,t,1:4])

      for (d in 1:4) {
        exp_p[s,t,d] <- exp(a[s,t,d] - amax[s,t])
      }

      denom[s,t] <- sum(exp_p[s,t,1:4])

      # P(choice=d) = exp(C*Q_d) / sum_k(exp(C*Q_k))
      for (d in 1:4) {
        p[s,t,d] <- exp_p[s,t,d] / denom[s,t]
      }

      x[s,t] ~ dcat(p[s,t,1:4])
    }
  }
}