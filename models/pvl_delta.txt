# PVL-Delta model
# prospect theory + delta learning rule
# from Steingroever et al 2013

model {
  # group means
  mu_w ~ dnorm(0,1)T(0,)        # loss aversion - >1 means losses hurt more
  mu_A ~ dnorm(0,1)             # outcome sensitivity (curvature of utility)
  mu_theta ~ dnorm(0,1)T(0,)    # inverse temperature
  mu_a ~ dnorm(0,1)T(0,1)       # learning rate

  # precision priors (hBayesDM style)
  lambda_w ~ dgamma(2.5/2,0.01/2)
  lambda_A ~ dgamma(2.5/2,0.01/2)
  lambda_theta ~ dgamma(2.5/2,0.01/2)
  lambda_a ~ dgamma(2.5/2,0.01/2)

  for (s in 1:nsubs) {
    # individual params
    w[s] ~ dnorm(mu_w, lambda_w)
    A[s] ~ dnorm(mu_A, lambda_A)
    theta[s] ~ dnorm(mu_theta, lambda_theta)T(0,)
    a[s] ~ dnorm(mu_a, lambda_a)
   
    # Ev starts with weak prior - lets it settle during burn-in
    Ev[s,1,1] ~ dnorm(0,0.01)
    Ev[s,1,2] ~ dnorm(0,0.01)
    Ev[s,1,3] ~ dnorm(0,0.01)
    Ev[s,1,4] ~ dnorm(0,0.01)
    
    for (t in 2:ntrials[s]) {
    
      for (d in 1:4) {
        # prospect theory utility - losses weighted by w, both curved by A
        u[s, t, d] <- ifelse(X[s, t-1] < 0, -w[s] * abs(X[s, t-1])^A[s], X[s,t-1]^A[s])
        
        # delta rule update - prediction error * learning rate
        Ev_update[s, t, d] <- Ev[s, t-1, d] + (a[s] * (u[s, t, d] - Ev[s, t-1, d]))
        
        # only update the deck that was actually chosen
        Ev[s,t,d] <- ifelse(x[s,t-1] == d, Ev_update[s,t,d], Ev[s, t-1, d])
        
        # softmax numerator
        exp_p[s, t, d] <- exp(theta[s]*Ev[s, t, d])
      }
    
      # normalize to get probabilities
      for (d in 1:4) {
        p[s, t, d] <- exp_p[s, t, d]/sum(exp_p[s, t, ])
      }
    
      x[s,t] ~ dcat(p[s,t, ])
    }
  }
}